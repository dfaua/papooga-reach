import { NextRequest, NextResponse } from "next/server";
import { validateApiKey } from "@/app/lib/auth/api-key";

const GEMINI_API_KEY = process.env.GEMINI_API_KEY;
const GROQ_API_KEY = process.env.GROQ_API_KEY;

interface PersonalizeRequest {
  template: string;
  person: {
    name: string;
    title: string | null;
  };
  company: {
    name: string;
    website: string | null;
    industry: string | null;
    employee_count: string | null;
    description: string | null;
    location: string | null;
  };
  profile: {
    roles: string[];
    pain_points: string[];
  };
  maxChars: number;
  model?: string;
  personalizationNote?: string;
}

// Available models configuration
const MODELS = {
  "gemini/gemini-3-flash-preview": {
    provider: "gemini",
    modelId: "gemini-3-flash-preview",
  },
  "groq/gpt-oss-20b": {
    provider: "groq",
    modelId: "openai/gpt-oss-20b",
  },
  "groq/llama-3.3-8b": {
    provider: "groq",
    modelId: "llama-3.3-8b-instant",
  },
  "groq/llama-3.3-70b": {
    provider: "groq",
    modelId: "llama-3.3-70b-versatile",
  },
  "groq/llama-4-scout": {
    provider: "groq",
    modelId: "llama-4-scout-17b-16e-instruct",
  },
};

type ModelKey = keyof typeof MODELS;

async function callGemini(systemPrompt: string, userPrompt: string, modelId: string): Promise<string> {
  const response = await fetch(
    `https://generativelanguage.googleapis.com/v1beta/models/${modelId}:generateContent?key=${GEMINI_API_KEY}`,
    {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
      },
      body: JSON.stringify({
        contents: [
          {
            role: "user",
            parts: [{ text: systemPrompt + "\n\n" + userPrompt }],
          },
        ],
        generationConfig: {
          temperature: 0.7,
          maxOutputTokens: 10240,
        },
      }),
    }
  );

  if (!response.ok) {
    const errorText = await response.text();
    console.error("Gemini API error:", errorText);
    throw new Error(`Gemini API error: ${response.status}`);
  }

  const data = await response.json();
  const generatedText = data.candidates?.[0]?.content?.parts?.[0]?.text;

  if (!generatedText) {
    console.error("No text in Gemini response:", data);
    throw new Error("No text generated by AI");
  }

  return generatedText;
}

async function callGroq(systemPrompt: string, userPrompt: string, modelId: string): Promise<string> {
  const response = await fetch("https://api.groq.com/openai/v1/chat/completions", {
    method: "POST",
    headers: {
      "Content-Type": "application/json",
      "Authorization": `Bearer ${GROQ_API_KEY}`,
    },
    body: JSON.stringify({
      model: modelId,
      messages: [
        { role: "system", content: systemPrompt },
        { role: "user", content: userPrompt },
      ],
      temperature: 0.7,
      max_tokens: 10240,
    }),
  });

  if (!response.ok) {
    const errorText = await response.text();
    console.error("Groq API error:", errorText);
    throw new Error(`Groq API error: ${response.status}`);
  }

  const data = await response.json();
  const generatedText = data.choices?.[0]?.message?.content;

  if (!generatedText) {
    console.error("No text in Groq response:", data);
    throw new Error("No text generated by AI");
  }

  return generatedText;
}

export async function POST(request: NextRequest) {
  const authError = validateApiKey(request);
  if (authError) return authError;

  const body: PersonalizeRequest = await request.json();
  const { template, person, company, profile, maxChars, model, personalizationNote } = body;

  // Get model config, default to gemini
  const modelKey = (model || "gemini/gemini-3-flash-preview") as ModelKey;
  const modelConfig = MODELS[modelKey];

  if (!modelConfig) {
    return NextResponse.json(
      { error: `Unknown model: ${model}` },
      { status: 400 }
    );
  }

  const systemPrompt = `You are an expert at personalizing LinkedIn outreach messages. Your task is to take a template message and personalize it for a specific person while preserving the original structure and tone.

Rules:
1. PRESERVE the overall structure, flow, and tone of the template
2. PERSONALIZE by incorporating specific details about the person and their company
3. Keep the message natural and conversational - avoid sounding robotic or overly formal
4. The final message MUST be under ${maxChars} characters
5. Do NOT add any placeholders like [Name] or {Company} - use the actual values
6. Return ONLY the personalized message, no explanations or commentary
7. You MUST return the complete message, no truncation or ellipses
8. Keep the message as close to the original template as possible
9. If you're using company name, no need to use parts like LTD, Inc., etc.`;

  let userPrompt = `Template to personalize:
"""
${template}
"""

Person Information:
- Name: ${person.name}
- Title: ${person.title || "Unknown"}

Company Information:
- Company: ${company.name}
- Website: ${company.website || "Not available"}
- Industry: ${company.industry || "Not specified"}
- Size: ${company.employee_count || "Not specified"}
- Location: ${company.location || "Not specified"}
- Description: ${company.description || "Not available"}

Target Profile Context:
- Target Roles: ${profile.roles.join(", ")}
- Known Pain Points for this role: ${profile.pain_points.length > 0 ? profile.pain_points.join("; ") : "Not specified"}`;

  // Add personalization note if provided
  if (personalizationNote && personalizationNote.trim()) {
    userPrompt += `

IMPORTANT - User's personalization note (incorporate this naturally into the message):
${personalizationNote.trim()}`;
  }

  userPrompt += `

Please personalize this template for ${person.name}. Keep under ${maxChars} characters.`;

  try {
    let generatedText: string;

    if (modelConfig.provider === "gemini") {
      generatedText = await callGemini(systemPrompt, userPrompt, modelConfig.modelId);
    } else if (modelConfig.provider === "groq") {
      generatedText = await callGroq(systemPrompt, userPrompt, modelConfig.modelId);
    } else {
      throw new Error(`Unknown provider: ${modelConfig.provider}`);
    }

    // Trim and ensure under max chars
    let personalizedMessage = generatedText.trim();
    if (personalizedMessage.length > maxChars) {
      // Truncate at last sentence or word boundary
      personalizedMessage = personalizedMessage.substring(0, maxChars - 3) + "...";
    }

    return NextResponse.json({ message: personalizedMessage });
  } catch (error) {
    console.error("AI personalization error:", error);
    return NextResponse.json(
      { error: error instanceof Error ? error.message : "Failed to personalize message" },
      { status: 500 }
    );
  }
}

// GET endpoint to list available models
export async function GET(request: NextRequest) {
  const authError = validateApiKey(request);
  if (authError) return authError;

  return NextResponse.json({
    models: Object.keys(MODELS),
    default: "gemini/gemini-3-flash-preview",
  });
}
